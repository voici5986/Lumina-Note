//! å·¥å…·æ³¨å†Œè¡¨
//! 
//! ç®¡ç†å·¥å…·çš„æ³¨å†Œå’Œæ‰§è¡Œ

use crate::agent::types::*;
use crate::agent::tools::fast_search::FastSearch;
use regex::Regex;
use std::collections::HashMap;
use std::path::Path;
use walkdir::WalkDir;

/// å·¥å…·æ³¨å†Œè¡¨
pub struct ToolRegistry {
    workspace_path: String,
}

impl ToolRegistry {
    pub fn new(workspace_path: String) -> Self {
        Self { workspace_path }
    }

    /// æ‰§è¡Œå·¥å…·
    pub async fn execute(&self, tool_call: &ToolCall) -> ToolResult {
        let result = match tool_call.name.as_str() {
            "read_note" => self.read_note(&tool_call.params).await,
            "read_outline" => self.read_outline(&tool_call.params).await,
            "read_section" => self.read_section(&tool_call.params).await,
            "edit_note" => self.edit_note(&tool_call.params).await,
            "create_note" => self.create_note(&tool_call.params).await,
            "list_notes" => self.list_notes(&tool_call.params).await,
            "search_notes" => self.search_notes(&tool_call.params).await,
            "fast_search" => self.fast_search(&tool_call.params).await,
            "grep_search" => self.grep_search(&tool_call.params).await,
            "semantic_search" => self.semantic_search(&tool_call.params).await,
            "move_note" => self.move_note(&tool_call.params).await,
            "delete_note" => self.delete_note(&tool_call.params).await,
            "query_database" => self.query_database(&tool_call.params).await,
            "add_database_row" => self.add_database_row(&tool_call.params).await,
            "get_backlinks" => self.get_backlinks(&tool_call.params).await,
            "ask_user" => self.ask_user(&tool_call.params).await,
            "attempt_completion" => self.attempt_completion(&tool_call.params).await,
            // update_plan åœ¨ agent_worker_node ä¸­ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œåªè¿”å›ç¡®è®¤
            "update_plan" => Ok("è®¡åˆ’å·²æ›´æ–°".to_string()),
            _ => Err(format!("Unknown tool: {}", tool_call.name)),
        };

        match result {
            Ok(content) => ToolResult {
                tool_call_id: tool_call.id.clone(),
                success: true,
                content,
                error: None,
            },
            Err(e) => ToolResult {
                tool_call_id: tool_call.id.clone(),
                success: false,
                content: String::new(),
                error: Some(e),
            },
        }
    }

    /// è·å–å®Œæ•´è·¯å¾„
    fn get_full_path(&self, relative_path: &str) -> String {
        let base = Path::new(&self.workspace_path);
        let rel = relative_path.trim_start_matches('/').trim_start_matches('\\');
        
        // å¦‚æœæ˜¯å½“å‰ç›®å½•æ ‡è¯†ç¬¦ï¼Œç›´æ¥è¿”å›å·¥ä½œåŒºè·¯å¾„
        if rel.is_empty() || rel == "." {
            return self.workspace_path.clone();
        }
        
        base.join(rel).to_string_lossy().to_string()
    }

    /// è¯»å–ç¬”è®°
    async fn read_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;

        let full_path = self.get_full_path(path);
        
        let content = tokio::fs::read_to_string(&full_path).await
            .map_err(|e| format!("Failed to read file: {}", e))?;

        // æ·»åŠ è¡Œå·
        let numbered = content.lines()
            .enumerate()
            .map(|(i, line)| format!("{:4} | {}", i + 1, line))
            .collect::<Vec<_>>()
            .join("\n");

        Ok(numbered)
    }

    /// æ‰¹é‡è¯»å–ç¬”è®°å¤§çº²
    async fn read_outline(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        use crate::agent::note_map::parser::{parse_markdown, extract_title};
        
        let paths = params.get("paths")
            .and_then(|v| v.as_array())
            .ok_or("Missing 'paths' parameter")?;
        
        let mut results = Vec::new();
        
        for path_value in paths {
            let path = path_value.as_str().ok_or("Invalid path in array")?;
            let full_path = self.get_full_path(path);
            let full_path_obj = Path::new(&full_path);
            
            // å¦‚æœæ˜¯ç›®å½•ï¼Œåˆ—å‡ºç›®å½•ä¸‹çš„ .md æ–‡ä»¶
            if full_path_obj.is_dir() {
                let mut dir_files = Vec::new();
                if let Ok(entries) = std::fs::read_dir(&full_path) {
                    for entry in entries.filter_map(|e| e.ok()) {
                        let entry_path = entry.path();
                        if entry_path.extension().map(|e| e == "md").unwrap_or(false) {
                            if let Some(name) = entry_path.file_name() {
                                dir_files.push(format!("  ğŸ“„ {}", name.to_string_lossy()));
                            }
                        }
                    }
                }
                if dir_files.is_empty() {
                    results.push(format!("ğŸ“ {} (ç©ºç›®å½•æˆ–æ—  .md æ–‡ä»¶)\n", path));
                } else {
                    results.push(format!("ğŸ“ {} ({} ä¸ªæ–‡ä»¶)\n{}\n", path, dir_files.len(), dir_files.join("\n")));
                }
                continue;
            }
            
            match tokio::fs::read_to_string(&full_path).await {
                Ok(content) => {
                    let title = extract_title(&content, path);
                    let (tags, links) = parse_markdown(&content, path);
                    
                    let mut outline = format!("ğŸ“„ {} ({})\n", path, title);
                    
                    // æ¸²æŸ“æ ‡é¢˜ç»“æ„
                    for tag in &tags {
                        let indent = "  ".repeat((tag.level - 1) as usize);
                        let prefix = "#".repeat(tag.level as usize);
                        outline.push_str(&format!(
                            "{}{}  {} (L{}, {}å­—)\n",
                            indent, prefix, tag.heading, tag.line, tag.word_count
                        ));
                    }
                    
                    // æ˜¾ç¤ºé“¾æ¥æ•°é‡
                    if !links.is_empty() {
                        outline.push_str(&format!("   â†’ {} ä¸ªå‡ºé“¾\n", links.len()));
                    }
                    
                    results.push(outline);
                }
                Err(e) => {
                    results.push(format!("âŒ {} - è¯»å–å¤±è´¥: {}\n", path, e));
                }
            }
        }
        
        Ok(results.join("\n"))
    }

    /// è¯»å–ç¬”è®°çš„æŒ‡å®šç« èŠ‚
    async fn read_section(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        use crate::agent::note_map::parser::parse_markdown;
        
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;
        let section = params.get("section")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'section' parameter")?;
        
        let full_path = self.get_full_path(path);
        let content = tokio::fs::read_to_string(&full_path).await
            .map_err(|e| format!("Failed to read file: {}", e))?;
        
        let (tags, _) = parse_markdown(&content, path);
        
        // æŸ¥æ‰¾åŒ¹é…çš„ç« èŠ‚
        let section_lower = section.to_lowercase();
        let matching_tag = tags.iter().find(|t| {
            t.heading.to_lowercase().contains(&section_lower)
        });
        
        match matching_tag {
            Some(tag) => {
                // æå–ç« èŠ‚å†…å®¹
                let section_content = if tag.end_offset > tag.start_offset && tag.end_offset <= content.len() {
                    &content[tag.start_offset..tag.end_offset]
                } else {
                    &content[tag.start_offset..]
                };
                
                // æ·»åŠ è¡Œå·
                let start_line = tag.line;
                let numbered = section_content.lines()
                    .enumerate()
                    .map(|(i, line)| format!("{:4} | {}", start_line + i, line))
                    .collect::<Vec<_>>()
                    .join("\n");
                
                Ok(format!(
                    "ç« èŠ‚: {} (ä»ç¬¬ {} è¡Œå¼€å§‹, {}å­—)\n\n{}",
                    tag.heading, tag.line, tag.word_count, numbered
                ))
            }
            None => {
                // åˆ—å‡ºå¯ç”¨ç« èŠ‚
                let available: Vec<String> = tags.iter()
                    .map(|t| format!("  - {} (L{})", t.heading, t.line))
                    .collect();
                
                Err(format!(
                    "æœªæ‰¾åˆ°ç« èŠ‚ '{}'ã€‚å¯ç”¨ç« èŠ‚:\n{}",
                    section,
                    available.join("\n")
                ))
            }
        }
    }

    /// ç¼–è¾‘ç¬”è®°
    async fn edit_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;
        let old_string = params.get("old_string")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'old_string' parameter")?;
        let new_string = params.get("new_string")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'new_string' parameter")?;

        let full_path = self.get_full_path(path);
        
        let content = tokio::fs::read_to_string(&full_path).await
            .map_err(|e| format!("Failed to read file: {}", e))?;

        // æ£€æŸ¥ old_string æ˜¯å¦å­˜åœ¨
        if !content.contains(old_string) {
            // å°è¯•æ‰¾å‡ºé—®é¢˜åŸå› 
            let old_trimmed = old_string.trim();
            let hint = if content.contains(old_trimmed) {
                "æç¤ºï¼šå»æ‰é¦–å°¾ç©ºç™½åèƒ½æ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ old_string çš„é¦–å°¾ç©ºæ ¼/æ¢è¡Œ"
            } else if content.to_lowercase().contains(&old_string.to_lowercase()) {
                "æç¤ºï¼šå¿½ç•¥å¤§å°å†™åèƒ½æ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥å¤§å°å†™æ˜¯å¦åŒ¹é…"
            } else {
                // æ˜¾ç¤ºæ–‡ä»¶çš„å‰å‡ è¡Œå¸®åŠ©å®šä½
                let preview: String = content.lines().take(10).collect::<Vec<_>>().join("\n");
                return Err(format!(
                    "ç¼–è¾‘å¤±è´¥ï¼šæ‰¾ä¸åˆ°è¦æ›¿æ¢çš„å†…å®¹ã€‚\n\n\
                     æ–‡ä»¶ï¼š{}\n\
                     æœç´¢å†…å®¹ï¼ˆå‰50å­—ç¬¦ï¼‰ï¼š{:?}\n\n\
                     å¯èƒ½åŸå› ï¼š\n\
                     1. å†…å®¹å·²è¢«ä¿®æ”¹ï¼Œè¯·é‡æ–° read_note è·å–æœ€æ–°å†…å®¹\n\
                     2. ç©ºæ ¼æˆ–æ¢è¡Œç¬¦ä¸åŒ¹é…ï¼ˆæ³¨æ„è¡Œæœ«ç©ºæ ¼ï¼‰\n\
                     3. ç‰¹æ®Šå­—ç¬¦è½¬ä¹‰é—®é¢˜\n\n\
                     æ–‡ä»¶å‰10è¡Œé¢„è§ˆï¼š\n{}",
                    path,
                    old_string.chars().take(50).collect::<String>(),
                    preview
                ));
            };
            return Err(format!(
                "ç¼–è¾‘å¤±è´¥ï¼šæ‰¾ä¸åˆ°è¦æ›¿æ¢çš„å†…å®¹ã€‚\n{}\n\nè¯·é‡æ–° read_note è·å–æœ€æ–°å†…å®¹åå†è¯•ã€‚",
                hint
            ));
        }

        // æ›¿æ¢
        let new_content = content.replacen(old_string, new_string, 1);
        
        tokio::fs::write(&full_path, &new_content).await
            .map_err(|e| format!("Failed to write file: {}", e))?;

        Ok(format!("Successfully edited {}", path))
    }

    /// åˆ›å»ºç¬”è®°
    async fn create_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;
        let content = params.get("content")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'content' parameter")?;

        let full_path = self.get_full_path(path);
        
        // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if Path::new(&full_path).exists() {
            return Err(format!("File already exists: {}", path));
        }

        // åˆ›å»ºçˆ¶ç›®å½•
        if let Some(parent) = Path::new(&full_path).parent() {
            tokio::fs::create_dir_all(parent).await
                .map_err(|e| format!("Failed to create directory: {}", e))?;
        }

        tokio::fs::write(&full_path, content).await
            .map_err(|e| format!("Failed to write file: {}", e))?;

        Ok(format!("Successfully created {}", path))
    }

    /// åˆ—å‡ºç¬”è®°
    async fn list_notes(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .unwrap_or(".");
        
        // æ˜¯å¦é€’å½’åˆ—å‡º
        let recursive = params.get("recursive")
            .and_then(|v| v.as_bool())
            .unwrap_or(false);
        
        // æœ€å¤§æ·±åº¦é™åˆ¶
        let max_depth = if recursive {
            params.get("max_depth")
                .and_then(|v| v.as_i64())
                .unwrap_or(3) as usize
        } else {
            1
        };

        let full_path = self.get_full_path(path);
        let base_path = Path::new(&full_path);
        
        let mut entries = Vec::new();
        
        let walker = WalkDir::new(&full_path)
            .max_depth(max_depth)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            let entry_path = entry.path();
            if entry_path == base_path {
                continue;
            }

            let name = entry.file_name().to_string_lossy().to_string();
            
            // è·³è¿‡éšè—æ–‡ä»¶
            if name.starts_with('.') {
                continue;
            }

            let is_dir = entry.file_type().is_dir();
            let prefix = if is_dir { "ğŸ“ " } else { "ğŸ“„ " };
            
            // é€’å½’æ¨¡å¼ä¸‹æ˜¾ç¤ºç›¸å¯¹è·¯å¾„
            if recursive {
                let rel_path = entry_path.strip_prefix(base_path)
                    .map(|p| p.to_string_lossy().to_string())
                    .unwrap_or_else(|_| name.clone());
                let indent = "  ".repeat(entry.depth().saturating_sub(1));
                entries.push(format!("{}{}{}", indent, prefix, rel_path));
            } else {
                entries.push(format!("{}{}", prefix, name));
            }
        }

        if !recursive {
            entries.sort();
        }
        
        if entries.is_empty() {
            Ok("(empty directory)".to_string())
        } else {
            Ok(entries.join("\n"))
        }
    }

    /// æœç´¢ç¬”è®°
    async fn search_notes(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let query = params.get("query")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'query' parameter")?;
        let limit = params.get("limit")
            .and_then(|v| v.as_i64())
            .unwrap_or(10) as usize;

        let query_lower = query.to_lowercase();
        let mut results = Vec::new();

        let walker = WalkDir::new(&self.workspace_path)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            if results.len() >= limit {
                break;
            }

            let path = entry.path();
            
            // åªæœç´¢ .md æ–‡ä»¶
            if !path.extension().map(|e| e == "md").unwrap_or(false) {
                continue;
            }

            // è·³è¿‡éšè—æ–‡ä»¶
            if path.to_string_lossy().contains("/.") || path.to_string_lossy().contains("\\.") {
                continue;
            }

            if let Ok(content) = std::fs::read_to_string(path) {
                if content.to_lowercase().contains(&query_lower) {
                    let relative = path.strip_prefix(&self.workspace_path)
                        .map(|p| p.to_string_lossy().to_string())
                        .unwrap_or_else(|_| path.to_string_lossy().to_string());
                    
                    // æ‰¾åˆ°åŒ¹é…çš„è¡Œ
                    let mut matches = Vec::new();
                    for (i, line) in content.lines().enumerate() {
                        if line.to_lowercase().contains(&query_lower) {
                            matches.push(format!("  Line {}: {}", i + 1, line.trim()));
                            if matches.len() >= 3 {
                                break;
                            }
                        }
                    }
                    
                    results.push(format!("ğŸ“„ {}\n{}", relative, matches.join("\n")));
                }
            }
        }

        if results.is_empty() {
            Ok(format!("No notes found containing '{}'", query))
        } else {
            Ok(results.join("\n\n"))
        }
    }

    /// ç§»åŠ¨ç¬”è®°
    async fn move_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let from_path = params.get("from_path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'from_path' parameter")?;
        let to_path = params.get("to_path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'to_path' parameter")?;

        let full_from = self.get_full_path(from_path);
        let full_to = self.get_full_path(to_path);

        // åˆ›å»ºç›®æ ‡ç›®å½•
        if let Some(parent) = Path::new(&full_to).parent() {
            tokio::fs::create_dir_all(parent).await
                .map_err(|e| format!("Failed to create directory: {}", e))?;
        }

        tokio::fs::rename(&full_from, &full_to).await
            .map_err(|e| format!("Failed to move file: {}", e))?;

        Ok(format!("Successfully moved {} to {}", from_path, to_path))
    }

    /// åˆ é™¤ç¬”è®°
    async fn delete_note(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;

        let full_path = self.get_full_path(path);

        // ç§»åŠ¨åˆ°å›æ”¶ç«™
        trash::delete(&full_path)
            .map_err(|e| format!("Failed to delete file: {}", e))?;

        Ok(format!("Successfully deleted {} (moved to trash)", path))
    }

    /// è¯¢é—®ç”¨æˆ·
    async fn ask_user(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let question = params.get("question")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'question' parameter")?;

        // è¿™ä¸ªå·¥å…·ä¼šè§¦å‘å‰ç«¯æ˜¾ç¤ºé—®é¢˜ï¼Œç­‰å¾…ç”¨æˆ·å›å¤
        // å®é™…çš„å›å¤ä¼šé€šè¿‡ continueWithAnswer ä¼ å…¥
        Ok(format!("[WAITING_FOR_USER] {}", question))
    }

    /// å®Œæˆä»»åŠ¡
    async fn attempt_completion(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let result = params.get("result")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'result' parameter")?;

        Ok(format!("[TASK_COMPLETED] {}", result))
    }

    /// Grep æœç´¢ï¼ˆæ­£åˆ™è¡¨è¾¾å¼æœç´¢ï¼‰
    async fn grep_search(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let pattern = params.get("pattern")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'pattern' parameter")?;
        let search_path = params.get("path")
            .and_then(|v| v.as_str())
            .unwrap_or(".");
        let case_sensitive = params.get("case_sensitive")
            .and_then(|v| v.as_bool())
            .unwrap_or(false);
        let limit = params.get("limit")
            .and_then(|v| v.as_i64())
            .unwrap_or(20) as usize;

        // æ„å»ºæ­£åˆ™è¡¨è¾¾å¼
        let regex = if case_sensitive {
            Regex::new(pattern)
        } else {
            Regex::new(&format!("(?i){}", pattern))
        }.map_err(|e| format!("Invalid regex pattern '{}': {}", pattern, e))?;

        let full_path = self.get_full_path(search_path);
        let mut results = Vec::new();
        let mut files_scanned = 0;

        // æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        if !Path::new(&full_path).exists() {
            return Ok(format!("Search path does not exist: {}", full_path));
        }

        let walker = WalkDir::new(&full_path)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            if results.len() >= limit {
                break;
            }

            let path = entry.path();
            
            // åªæœç´¢ .md æ–‡ä»¶
            if !path.extension().map(|e| e == "md").unwrap_or(false) {
                continue;
            }

            // è·³è¿‡éšè—æ–‡ä»¶å’Œç‰¹æ®Šç›®å½•
            let path_str = path.to_string_lossy();
            if path_str.contains("/.") || path_str.contains("\\.") {
                continue;
            }
            // è·³è¿‡ .obsidian ç›®å½•
            if path_str.contains(".obsidian") || path_str.contains(".lumina") {
                continue;
            }

            files_scanned += 1;

            if let Ok(content) = std::fs::read_to_string(path) {
                let mut file_matches = Vec::new();
                
                for (i, line) in content.lines().enumerate() {
                    if regex.is_match(line) {
                        file_matches.push(format!("  {}:{} {}", i + 1, ":", line.trim()));
                        if file_matches.len() >= 5 {
                            break;
                        }
                    }
                }

                if !file_matches.is_empty() {
                    let relative = path.strip_prefix(&self.workspace_path)
                        .map(|p| p.to_string_lossy().to_string())
                        .unwrap_or_else(|_| path.to_string_lossy().to_string());
                    
                    results.push(format!("ğŸ“„ {}\n{}", relative, file_matches.join("\n")));
                }
            }
        }

        if results.is_empty() {
            Ok(format!("No matches found for '{}' (scanned {} files in '{}', full_path='{}')", 
                pattern, files_scanned, search_path, full_path))
        } else {
            Ok(format!("Found {} files matching '{}' (scanned {} files):\n\n{}", results.len(), pattern, files_scanned, results.join("\n\n")))
        }
    }

    /// å¿«é€Ÿæœç´¢ï¼ˆå¹¶è¡Œå­ä»£ç†ï¼‰
    async fn fast_search(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let keywords: Vec<String> = params.get("keywords")
            .and_then(|v| v.as_array())
            .map(|arr| arr.iter()
                .filter_map(|v| v.as_str().map(|s| s.to_string()))
                .collect())
            .ok_or("Missing 'keywords' parameter (should be an array of strings)")?;

        if keywords.is_empty() {
            return Err("keywords array cannot be empty".to_string());
        }

        // ä½¿ç”¨ FastSearch å­ä»£ç†æ‰§è¡Œå¹¶è¡Œæœç´¢
        let searcher = FastSearch::new(&self.workspace_path);
        let result = searcher.search_keywords(&keywords);
        
        Ok(result.format())
    }

    /// è¯­ä¹‰æœç´¢ï¼ˆå‘é‡æœç´¢ï¼‰
    async fn semantic_search(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let query = params.get("query")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'query' parameter")?;
        let limit = params.get("limit")
            .and_then(|v| v.as_i64())
            .unwrap_or(5) as usize;

        // TODO: è°ƒç”¨ vector_db è¿›è¡Œè¯­ä¹‰æœç´¢
        // ç›®å‰å…ˆè¿”å›æç¤ºä¿¡æ¯ï¼Œåç»­é›†æˆ RAG ç³»ç»Ÿ
        Ok(format!(
            "[SEMANTIC_SEARCH] Query: '{}', Limit: {}\n\
            Note: Semantic search requires RAG indexing. Please use search_notes or grep_search for now.",
            query, limit
        ))
    }

    /// æŸ¥è¯¢æ•°æ®åº“
    async fn query_database(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let database_id = params.get("database_id")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'database_id' parameter")?;
        let filter = params.get("filter")
            .and_then(|v| v.as_object());
        let limit = params.get("limit")
            .and_then(|v| v.as_i64())
            .unwrap_or(50) as usize;

        // è¯»å–æ•°æ®åº“å®šä¹‰æ–‡ä»¶
        let db_file = format!("{}.db.json", database_id);
        let db_path = self.get_full_path(&db_file);
        
        let db_content = tokio::fs::read_to_string(&db_path).await
            .map_err(|e| format!("Failed to read database '{}': {}", database_id, e))?;
        
        let db: serde_json::Value = serde_json::from_str(&db_content)
            .map_err(|e| format!("Failed to parse database: {}", e))?;

        // è·å–åˆ—å®šä¹‰
        let columns = db.get("columns")
            .and_then(|v| v.as_array())
            .ok_or("Invalid database format: missing columns")?;

        let column_names: Vec<String> = columns.iter()
            .filter_map(|c| c.get("name").and_then(|n| n.as_str()).map(|s| s.to_string()))
            .collect();

        // æ‰«æç¬”è®°åº“æŸ¥æ‰¾å±äºæ­¤æ•°æ®åº“çš„ç¬”è®°
        let mut rows = Vec::new();
        let walker = WalkDir::new(&self.workspace_path)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            if rows.len() >= limit {
                break;
            }

            let path = entry.path();
            if !path.extension().map(|e| e == "md").unwrap_or(false) {
                continue;
            }

            if let Ok(content) = std::fs::read_to_string(path) {
                // è§£æ frontmatter
                if let Some(fm) = Self::parse_frontmatter(&content) {
                    // æ£€æŸ¥æ˜¯å¦å±äºæ­¤æ•°æ®åº“
                    if fm.get("db").and_then(|v| v.as_str()) == Some(database_id) {
                        // åº”ç”¨è¿‡æ»¤å™¨
                        let mut matches = true;
                        if let Some(filter_obj) = filter {
                            for (key, value) in filter_obj {
                                if let Some(fm_value) = fm.get(key) {
                                    if fm_value != value {
                                        matches = false;
                                        break;
                                    }
                                } else {
                                    matches = false;
                                    break;
                                }
                            }
                        }

                        if matches {
                            let title = fm.get("title")
                                .and_then(|v| v.as_str())
                                .unwrap_or("Untitled");
                            
                            let mut row_data = vec![title.to_string()];
                            for col in &column_names {
                                let value = fm.get(col)
                                    .map(|v| match v {
                                        serde_json::Value::String(s) => s.clone(),
                                        _ => v.to_string(),
                                    })
                                    .unwrap_or_else(|| "-".to_string());
                                row_data.push(value);
                            }
                            rows.push(row_data);
                        }
                    }
                }
            }
        }

        // æ ¼å¼åŒ–è¾“å‡º
        if rows.is_empty() {
            Ok(format!("Database '{}' has no matching rows.", database_id))
        } else {
            let header = format!("| Title | {} |", column_names.join(" | "));
            let separator = format!("|{}|", vec!["---"; column_names.len() + 1].join("|"));
            let body: Vec<String> = rows.iter()
                .map(|row| format!("| {} |", row.join(" | ")))
                .collect();
            
            Ok(format!("{}\n{}\n{}", header, separator, body.join("\n")))
        }
    }

    /// æ·»åŠ æ•°æ®åº“è¡Œ
    async fn add_database_row(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let database_id = params.get("database_id")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'database_id' parameter")?;
        let title = params.get("title")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'title' parameter")?;
        let cells = params.get("cells")
            .and_then(|v| v.as_object());

        // æ„å»º frontmatter
        let mut frontmatter = format!("---\ndb: {}\ntitle: {}\n", database_id, title);
        
        if let Some(cells_obj) = cells {
            for (key, value) in cells_obj {
                let value_str = match value {
                    serde_json::Value::String(s) => s.clone(),
                    _ => value.to_string(),
                };
                frontmatter.push_str(&format!("{}: {}\n", key, value_str));
            }
        }
        frontmatter.push_str("---\n\n");

        // åˆ›å»ºç¬”è®°æ–‡ä»¶
        let safe_title = title.replace(['/', '\\', ':', '*', '?', '"', '<', '>', '|'], "_");
        let note_path = format!("{}.md", safe_title);
        let full_path = self.get_full_path(&note_path);

        if Path::new(&full_path).exists() {
            return Err(format!("Note '{}' already exists", note_path));
        }

        let content = format!("{}# {}\n\n", frontmatter, title);
        tokio::fs::write(&full_path, &content).await
            .map_err(|e| format!("Failed to create note: {}", e))?;

        Ok(format!("Successfully added row '{}' to database '{}'", title, database_id))
    }

    /// è·å–åå‘é“¾æ¥
    async fn get_backlinks(&self, params: &HashMap<String, serde_json::Value>) -> Result<String, String> {
        let path = params.get("path")
            .and_then(|v| v.as_str())
            .ok_or("Missing 'path' parameter")?;

        // è·å–ç¬”è®°åï¼ˆä¸å«è·¯å¾„å’Œæ‰©å±•åï¼‰
        let note_name = Path::new(path)
            .file_stem()
            .and_then(|s| s.to_str())
            .ok_or("Invalid path")?;

        // æ„å»ºåŒ¹é…æ¨¡å¼ï¼š[[note_name]] æˆ– [[note_name|alias]]
        let pattern = format!(r"\[\[{}(\|[^\]]+)?\]\]", regex::escape(note_name));
        let regex = Regex::new(&pattern).map_err(|e| format!("Regex error: {}", e))?;

        let mut backlinks = Vec::new();

        let walker = WalkDir::new(&self.workspace_path)
            .into_iter()
            .filter_map(|e| e.ok());

        for entry in walker {
            let entry_path = entry.path();
            
            // åªæœç´¢ .md æ–‡ä»¶ï¼Œä¸”ä¸æ˜¯è‡ªå·±
            if !entry_path.extension().map(|e| e == "md").unwrap_or(false) {
                continue;
            }

            let entry_relative = entry_path.strip_prefix(&self.workspace_path)
                .map(|p| p.to_string_lossy().to_string())
                .unwrap_or_default();

            // è·³è¿‡è‡ªå·±
            if entry_relative == path {
                continue;
            }

            // è·³è¿‡éšè—æ–‡ä»¶
            if entry_relative.contains("/.") || entry_relative.contains("\\.") {
                continue;
            }

            if let Ok(content) = std::fs::read_to_string(entry_path) {
                if regex.is_match(&content) {
                    // æ‰¾åˆ°åŒ…å«é“¾æ¥çš„è¡Œ
                    let mut context_lines = Vec::new();
                    for (i, line) in content.lines().enumerate() {
                        if regex.is_match(line) {
                            context_lines.push(format!("  Line {}: {}", i + 1, line.trim()));
                            if context_lines.len() >= 2 {
                                break;
                            }
                        }
                    }
                    
                    backlinks.push(format!("ğŸ“„ {}\n{}", entry_relative, context_lines.join("\n")));
                }
            }
        }

        if backlinks.is_empty() {
            Ok(format!("No backlinks found for '{}'", note_name))
        } else {
            Ok(format!("Found {} notes linking to '{}':\n\n{}", backlinks.len(), note_name, backlinks.join("\n\n")))
        }
    }

    /// è§£æ YAML frontmatter
    fn parse_frontmatter(content: &str) -> Option<serde_json::Map<String, serde_json::Value>> {
        let content = content.trim();
        if !content.starts_with("---") {
            return None;
        }

        let rest = &content[3..];
        let end_pos = rest.find("\n---")?;
        let yaml_str = &rest[..end_pos];

        // ç®€å•è§£æ YAML
        let mut map = serde_json::Map::new();
        for line in yaml_str.lines() {
            let line = line.trim();
            if line.is_empty() || line.starts_with('#') {
                continue;
            }
            if let Some(colon_pos) = line.find(':') {
                let key = line[..colon_pos].trim().to_string();
                let value = line[colon_pos + 1..].trim().to_string();
                map.insert(key, serde_json::Value::String(value));
            }
        }

        Some(map)
    }
}
