//! Fast Search å­ä»£ç† - ç±»ä¼¼ Windsurf Fast Context
//! é€šè¿‡å¹¶è¡Œ grep å¿«é€Ÿæœç´¢ç¬”è®°åº“ï¼Œä¸ç»è¿‡ LLM

use std::path::Path;
use walkdir::WalkDir;
use rayon::prelude::*;

/// æœç´¢ç»“æœ
#[derive(Debug, Clone)]
pub struct SearchResult {
    pub files: Vec<FileMatch>,
    pub files_scanned: usize,
    pub duration_ms: u64,
    pub keywords_used: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct FileMatch {
    pub path: String,
    pub keyword_hits: usize,
    pub lines: Vec<LineMatch>,
}

#[derive(Debug, Clone)]
pub struct LineMatch {
    pub line_number: usize,
    pub content: String,
    pub keyword: String,
}

/// Fast Search å­ä»£ç†
pub struct FastSearch {
    workspace_path: String,
}

impl FastSearch {
    pub fn new(workspace_path: &str) -> Self {
        Self { workspace_path: workspace_path.to_string() }
    }

    /// ä½¿ç”¨ LLM æå–çš„å…³é”®è¯æ‰§è¡Œå¿«é€Ÿæœç´¢
    pub fn search_keywords(&self, keywords: &[String]) -> SearchResult {
        let start = std::time::Instant::now();
        
        if keywords.is_empty() {
            return SearchResult {
                files: vec![],
                files_scanned: 0,
                duration_ms: start.elapsed().as_millis() as u64,
                keywords_used: vec![],
            };
        }

        // 1. æ”¶é›†æ‰€æœ‰ .md æ–‡ä»¶
        let md_files = self.collect_md_files();
        let files_scanned = md_files.len();

        // 2. å¹¶è¡Œæœç´¢ï¼ˆä½¿ç”¨ rayonï¼‰
        let file_matches: Vec<FileMatch> = md_files.par_iter()
            .filter_map(|file_path| {
                self.search_file(file_path, keywords)
            })
            .collect();

        // 3. æ’åºï¼šæŒ‰å…³é”®è¯å‘½ä¸­æ•°é™åº
        let mut sorted: Vec<_> = file_matches.into_iter()
            .filter(|m| !m.lines.is_empty())
            .collect();
        sorted.sort_by(|a, b| b.keyword_hits.cmp(&a.keyword_hits));
        sorted.truncate(20);

        SearchResult {
            files: sorted,
            files_scanned,
            duration_ms: start.elapsed().as_millis() as u64,
            keywords_used: keywords.to_vec(),
        }
    }

    /// æ‰§è¡Œå¿«é€Ÿæœç´¢ï¼ˆè‡ªåŠ¨æå–å…³é”®è¯ï¼Œå¤‡ç”¨ï¼‰
    #[allow(dead_code)]
    pub fn search(&self, query: &str) -> SearchResult {
        let keywords = extract_keywords(query);
        self.search_keywords(&keywords)
    }

    fn collect_md_files(&self) -> Vec<String> {
        WalkDir::new(&self.workspace_path)
            .into_iter()
            .filter_map(|e| e.ok())
            .filter(|e| {
                let path = e.path();
                let path_str = path.to_string_lossy();
                path.extension().map(|e| e == "md").unwrap_or(false)
                    && !path_str.contains(".obsidian")
                    && !path_str.contains(".lumina")
                    && !path_str.contains("/.")
                    && !path_str.contains("\\.")
            })
            .map(|e| e.path().to_string_lossy().to_string())
            .collect()
    }

    fn search_file(&self, file_path: &str, keywords: &[String]) -> Option<FileMatch> {
        let content = std::fs::read_to_string(file_path).ok()?;
        let mut lines = Vec::new();
        let mut keyword_set = std::collections::HashSet::new();

        for (i, line) in content.lines().enumerate() {
            for kw in keywords {
                if line.to_lowercase().contains(&kw.to_lowercase()) {
                    keyword_set.insert(kw.clone());
                    lines.push(LineMatch {
                        line_number: i + 1,
                        content: line.chars().take(200).collect(),
                        keyword: kw.clone(),
                    });
                    if lines.len() >= 10 { break; }
                }
            }
            if lines.len() >= 10 { break; }
        }

        if lines.is_empty() { return None; }

        let relative = Path::new(file_path)
            .strip_prefix(&self.workspace_path)
            .map(|p| p.to_string_lossy().to_string())
            .unwrap_or_else(|_| file_path.to_string());

        Some(FileMatch {
            path: relative,
            keyword_hits: keyword_set.len(),
            lines,
        })
    }
}

/// ä»æŸ¥è¯¢ä¸­æå–å…³é”®è¯
fn extract_keywords(query: &str) -> Vec<String> {
    // ä¸­æ–‡åœç”¨è¯ï¼ˆå•å­—ï¼‰- ç”¨äºåˆ†å‰²
    let chinese_stopwords: std::collections::HashSet<char> = [
        'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'éƒ½', 'ä¸€', 'ä¸ª',
        'è¿™', 'é‚£', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'ä»¬', 'ä¸', 'åŠ', 'æˆ–', 'ç­‰', 'æŠŠ',
        'è¢«', 'è®©', 'ç»™', 'å‘', 'ä»', 'åˆ°', 'ä¸º', 'ä»¥', 'äº', 'è€Œ', 'ä¸”', 'ä½†',
    ].into_iter().collect();
    
    // å¤šå­—åœç”¨è¯
    let stopwords: std::collections::HashSet<&str> = [
        "æœç´¢", "æŸ¥æ‰¾", "æ‰¾åˆ°", "ç›¸å…³", "å…³äº", "å…¨éƒ¨", "æ‰€æœ‰", "å¸®æˆ‘", "è¯·é—®",
        "ä»€ä¹ˆ", "æ€ä¹ˆ", "å¦‚ä½•", "å“ªäº›", "å“ªä¸ª", "å¯ä»¥", "èƒ½å¤Ÿ", "éœ€è¦",
        "the", "a", "an", "is", "are", "for", "all", "search", "find",
    ].into_iter().collect();

    let mut keywords = Vec::new();
    let mut current = String::new();
    
    for c in query.chars() {
        let is_chinese = c >= '\u{4e00}' && c <= '\u{9fff}';
        
        // ä¸­æ–‡åœç”¨è¯å­—ç¬¦ä½œä¸ºåˆ†éš”ç¬¦
        if is_chinese && chinese_stopwords.contains(&c) {
            if !current.is_empty() && current.chars().count() > 1 {
                if !stopwords.contains(current.as_str()) {
                    keywords.push(current.clone());
                }
            }
            current.clear();
        } else if c.is_alphanumeric() || is_chinese {
            current.push(c);
        } else {
            // éå­—æ¯æ•°å­—éä¸­æ–‡ä½œä¸ºåˆ†éš”ç¬¦
            if !current.is_empty() && current.chars().count() > 1 {
                if !stopwords.contains(current.as_str()) {
                    keywords.push(current.clone());
                }
            }
            current.clear();
        }
    }
    
    // å¤„ç†æœ€åä¸€ä¸ªè¯
    if !current.is_empty() && current.chars().count() > 1 {
        if !stopwords.contains(current.as_str()) {
            keywords.push(current);
        }
    }

    // å»é‡å¹¶é™åˆ¶æ•°é‡
    let mut unique: Vec<String> = Vec::new();
    for kw in keywords {
        if !unique.contains(&kw) {
            unique.push(kw);
        }
    }
    
    unique.into_iter().take(8).collect()
}

impl SearchResult {
    /// æ ¼å¼åŒ–ä¸ºå·¥å…·è¿”å›æ ¼å¼
    pub fn format(&self) -> String {
        if self.files.is_empty() {
            return format!(
                "No matches found (scanned {} files in {}ms, keywords: {:?})",
                self.files_scanned, self.duration_ms, self.keywords_used
            );
        }

        let mut output = format!(
            "Found {} files (scanned {} files in {}ms, keywords: {:?}):\n\n",
            self.files.len(), self.files_scanned, self.duration_ms, self.keywords_used
        );

        for file in &self.files {
            output.push_str(&format!("ğŸ“„ {} ({}ä¸ªå…³é”®è¯å‘½ä¸­)\n", file.path, file.keyword_hits));
            for line in &file.lines {
                output.push_str(&format!("  L{}: {}\n", line.line_number, line.content));
            }
            output.push('\n');
        }

        output
    }
}
